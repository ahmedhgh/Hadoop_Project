# Hadoop_Project

# Hadoop Presentation:

https://docs.google.com/presentation/d/17CooF-cfo1g4TdGzIDgM92bdN_VIG2F-reo9zXcPMEc/edit?usp=sharing

# Hadoop installation:
https://github.com/ahmedhgh/hadoop_project/blob/master/Installing%20and%20Practicing%20Hadoop%20in%20Jupyter%20Notebook.ipynb

# Hadoop Project: 
# 1- Processing and Creating Predictive models for Academic Buildings by Using Bigdata Technology (Regression Problem)
https://github.com/ahmedhgh/Hadoop_Project/blob/master/Proj_part1_Ahmed_Ghareeb.ipynb

# 2 - Gas sensors for home activity monitoring Data Set (Classification Problem)Â¶
https://github.com/ahmedhgh/Hadoop_Project/blob/master/Database_Project.ipynb

In this project the University of Dayton campus buildings selected to develop and validate the knowledge
discovery models to understand the behavior of energy consumption, we will use the campus buildings to
understand the underlying behavior and attempt to use knowledge discovery methods (KDD) to gain
knowledge about various campus buildings.

Certainly, the behavior of building will depend on the activities that occur in it. For instance, the activities
in the library building will appear to be more energy consuming during the weekends, classrooms more
occupied during the class time which will vary roughly from 8 A.M to 12 P.M. and so on.
One of the important values we can get from this project using the knowledge discovery in addition to the
general building behavior is the range and the amount of energy for the specific hour.
Another important task in buildings is accurate energy prediction; this is useful because the institution
owners need to make sure that they have the amount of energy needed at the particular time. Due to
energy deregulation plan the building owners need to submit the amount of energy needed for the next 24
hours to the utility providers (short-term prediction requirement), or they need to know how much energy
needed at each building monthly (medium-term prediction), and the amount of energy needed if they plan
to extend the institute or plan for policy.
Before we describe the tasks we will use to accomplish the above-mentioned problems, we will describe
the datasets.

Using Bigdata Technology (Hadoop and Spark) we can accelerate the process of predictive models by putting them in the external server or distribute them to be processed in parallel in and out core instead of traditional computing.

# Description of Data:
The data sets are consist of energy consumption for the academic building, and the individual dataset
includes one building with consumption for one year with outside air temperature, day, hour, and
workday or not. We separated the datasets to be easily interpretable, so for one month the size of the
dataset is (2976 samples X 6 attributes). The current finished task building is the library (Roesch Library).
The analysis performed and the predictive model created can be extended to other university buildings as
well.
